"""
æ·±åº¦ä¼°å€¼æŠ¥å‘Šç³»ç»Ÿ - ä¸»ç¨‹åº
æ•´åˆSonarå®æ—¶æœç´¢å’ŒQwen3Maxæ·±åº¦æ¨ç†
"""
import time
from datetime import datetime
from typing import Optional
from agents import QueryPlannerAgent, InformationCollectorAgent, DeepAnalystAgent
from agents.professional_formatter import ProfessionalReportFormatter
from api_clients import SonarClient, QwenClient


class ValuationReportSystem:
    """
    ä¼°å€¼æŠ¥å‘Šç³»ç»Ÿä¸»ç±»
    
    æ¶æ„ï¼š
    1. QueryPlanner (Qwenè½»é‡) -> ç”Ÿæˆç²¾ç¡®æŸ¥è¯¢è®¡åˆ’
    2. InformationCollector (Sonarå¹¶è¡Œ) -> æ”¶é›†å®æ—¶ä¿¡æ¯
    3. DeepAnalyst (Qwenæ·±åº¦) -> ç”Ÿæˆä¸“ä¸šæŠ¥å‘Š
    """
    
    def __init__(self):
        # åˆå§‹åŒ–APIå®¢æˆ·ç«¯
        self.sonar_client = SonarClient()
        self.qwen_client = QwenClient()
        
        # åˆå§‹åŒ–Agents
        self.query_planner = QueryPlannerAgent(self.qwen_client)
        self.information_collector = InformationCollectorAgent(self.sonar_client)
        self.deep_analyst = DeepAnalystAgent(self.qwen_client)
        self.professional_formatter = ProfessionalReportFormatter()
        
    def generate_report(
        self,
        company: str,
        analysis_type: str = "valuation",
        report_type: str = "comprehensive",
        save_to_file: bool = True,
        generate_pdf: bool = True,  # é»˜è®¤ç”ŸæˆPDF
        keep_markdown: bool = True  # æ˜¯å¦ä¿ç•™Markdownæ–‡ä»¶
    ) -> dict:
        """
        ç”Ÿæˆå®Œæ•´çš„ä¼°å€¼æŠ¥å‘Š
        
        Args:
            company: å…¬å¸åç§°æˆ–è‚¡ç¥¨ä»£ç 
            analysis_type: åˆ†æç±»å‹
            report_type: æŠ¥å‘Šç±»å‹ï¼ˆcomprehensive=ç»¼åˆ, quick=å¿«é€Ÿï¼‰
            save_to_file: æ˜¯å¦ä¿å­˜åˆ°æ–‡ä»¶
            generate_pdf: æ˜¯å¦ç”ŸæˆPDFç‰ˆæœ¬ï¼ˆé»˜è®¤Trueï¼‰
            keep_markdown: æ˜¯å¦ä¿ç•™Markdownæ–‡ä»¶ï¼ˆé»˜è®¤Trueï¼‰
            
        Returns:
            åŒ…å«æŠ¥å‘Šå†…å®¹çš„å­—å…¸
        """
        print("="*80)
        print(f"ğŸš€ æ·±åº¦ä¼°å€¼æŠ¥å‘Šç³»ç»Ÿ")
        print(f"ğŸ“Š åˆ†æå¯¹è±¡: {company}")
        print(f"â° å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("="*80)
        
        start_time = time.time()
        
        # é˜¶æ®µ1: æŸ¥è¯¢è§„åˆ’ï¼ˆQwenè½»é‡è°ƒç”¨ï¼‰
        print("\nã€é˜¶æ®µ1/3ã€‘æŸ¥è¯¢è§„åˆ’")
        print("-"*80)
        query_plan = self.query_planner.generate_search_plan(company, analysis_type)
        
        if query_plan["status"] != "success":
            return {"status": "error", "error": "æŸ¥è¯¢è§„åˆ’å¤±è´¥"}
        
        print(f"âœ… ç”Ÿæˆäº† {len(query_plan['plan']['queries'])} ä¸ªæœç´¢æŸ¥è¯¢")
        for i, q in enumerate(query_plan['plan']['queries'], 1):
            print(f"   {i}. [{q['priority']}] {q['purpose']}: {q['query'][:60]}...")
        
        # é˜¶æ®µ2: ä¿¡æ¯æ”¶é›†ï¼ˆSonarå¹¶è¡Œè°ƒç”¨ï¼‰
        print("\nã€é˜¶æ®µ2/3ã€‘ä¿¡æ¯æ”¶é›†")
        print("-"*80)
        collection_result = self.information_collector.collect_information(query_plan)
        
        if collection_result["status"] != "success":
            return {"status": "error", "error": "ä¿¡æ¯æ”¶é›†å¤±è´¥"}
        
        # æ ¼å¼åŒ–ä¿¡æ¯ç”¨äºåˆ†æ
        formatted_info = self.information_collector.format_for_analysis(collection_result)
        
        # é˜¶æ®µ3: æ·±åº¦åˆ†æï¼ˆQwenæ·±åº¦æ¨ç†ï¼‰
        print("\nã€é˜¶æ®µ3/3ã€‘æ·±åº¦åˆ†æ")
        print("-"*80)
        
        if report_type == "quick":
            analysis_result = self.deep_analyst.generate_quick_summary(company, formatted_info)
        else:
            analysis_result = self.deep_analyst.generate_valuation_report(
                company,
                formatted_info,
                report_type
            )
        
        if analysis_result["status"] != "success":
            error_msg = analysis_result.get("error", "æœªçŸ¥é”™è¯¯")
            print(f"âŒ æ·±åº¦åˆ†æé”™è¯¯è¯¦æƒ…: {error_msg}")
            return {"status": "error", "error": f"æ·±åº¦åˆ†æå¤±è´¥: {error_msg}"}
        
        # è®¡ç®—æ€»è€—æ—¶
        elapsed_time = time.time() - start_time
        
        # å¦‚æœæŠ¥å‘ŠåŒ…å«JSONï¼Œæ›´æ–°å…ƒæ•°æ®å¹¶é‡æ–°æ ¼å¼åŒ–
        if "report_json" in analysis_result and analysis_result.get("report_json"):
            metadata = {
                "elapsed_time": elapsed_time,
                "queries_successful": collection_result["success_count"],
                "queries_executed": collection_result["total_queries"]
            }
            
            # æ”¶é›†æ‰€æœ‰citations
            all_citations = []
            for result in collection_result.get("results", []):
                if result.get("status") == "success" and result.get("citations"):
                    for citation in result["citations"]:
                        if citation not in all_citations:  # å»é‡
                            all_citations.append(citation)
            
            # é‡æ–°ç”Ÿæˆä¸“ä¸šæ ¼å¼æŠ¥å‘Šï¼ˆå¸¦æ­£ç¡®çš„å…ƒæ•°æ®å’Œcitationsï¼‰
            analysis_result["report"] = self.professional_formatter.format_professional_report(
                company,
                analysis_result["report_json"],
                metadata,
                citations=all_citations
            )
        
        print("\n" + "="*80)
        print(f"âœ… æŠ¥å‘Šç”Ÿæˆå®Œæˆ!")
        print(f"â±ï¸  æ€»è€—æ—¶: {elapsed_time:.2f}ç§’")
        print("="*80)
        
        # å‡†å¤‡è¾“å‡ºç»“æœ
        result = {
            "status": "success",
            "company": company,
            "report": analysis_result.get("report") or analysis_result.get("summary"),
            "metadata": {
                "analysis_type": analysis_type,
                "report_type": report_type,
                "queries_executed": collection_result["total_queries"],
                "queries_successful": collection_result["success_count"],
                "elapsed_time": elapsed_time,
                "timestamp": datetime.now().isoformat()
            }
        }
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        if save_to_file:
            filename = self._save_report(company, result)
            result["metadata"]["saved_file"] = filename
            
            # ç”ŸæˆPDFï¼ˆé»˜è®¤å¯ç”¨ï¼‰
            if generate_pdf:
                pdf_filename = self._generate_pdf_report(filename, company, analysis_result.get("report_json"))
                if pdf_filename:
                    result["metadata"]["pdf_file"] = pdf_filename
                    print(f"ğŸ“„ PDFæŠ¥å‘Šå·²ç”Ÿæˆ: {pdf_filename}")
                    
                    # å¦‚æœä¸ä¿ç•™Markdownï¼Œåˆ é™¤å®ƒ
                    if not keep_markdown:
                        import os
                        try:
                            os.remove(filename)
                            # åŒæ—¶åˆ é™¤enhancedç‰ˆæœ¬ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                            enhanced_file = filename.replace('.md', '_enhanced.md')
                            if os.path.exists(enhanced_file):
                                os.remove(enhanced_file)
                            print(f"ğŸ—‘ï¸  å·²åˆ é™¤ä¸´æ—¶Markdownæ–‡ä»¶")
                            result["metadata"].pop("saved_file", None)
                        except Exception as e:
                            print(f"âš ï¸  åˆ é™¤Markdownæ–‡ä»¶å¤±è´¥: {e}")
                else:
                    print(f"âš ï¸  PDFç”Ÿæˆå¤±è´¥ï¼Œä¿ç•™Markdown: {filename}")
            else:
                print(f"ğŸ’¾ MarkdownæŠ¥å‘Šå·²ä¿å­˜: {filename}")
        
        return result
    
    def _save_report(self, company: str, result: dict) -> str:
        """ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶ï¼ˆè‡ªåŠ¨æ ¼å¼åŒ–ï¼‰"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        safe_company = company.replace(" ", "_").replace("/", "_")
        filename = f"reports/{safe_company}_{timestamp}.md"
        
        # åˆ›å»ºreportsç›®å½•
        import os
        os.makedirs("reports", exist_ok=True)
        
        # å‡†å¤‡æŠ¥å‘Šå†…å®¹
        report_content = f"# {company} ä¼°å€¼æŠ¥å‘Š\n\n"
        report_content += f"**ç”Ÿæˆæ—¶é—´**: {result['metadata']['timestamp']}\n\n"
        report_content += f"**åˆ†æç±»å‹**: {result['metadata']['analysis_type']} | "
        report_content += f"**æŸ¥è¯¢æ•°**: {result['metadata']['queries_successful']}/{result['metadata']['queries_executed']} | "
        report_content += f"**è€—æ—¶**: {result['metadata']['elapsed_time']:.2f}ç§’\n\n"
        report_content += "---\n\n"
        report_content += result["report"]
        
        # æ ¼å¼åŒ–æŠ¥å‘Šï¼ˆè½¬æ¢HTMLè¡¨æ ¼ä¸ºMarkdownï¼‰
        formatted_content = self._format_report_content(report_content)
        
        # å†™å…¥æŠ¥å‘Š
        with open(filename, "w", encoding="utf-8") as f:
            f.write(formatted_content)
        
        # ğŸ†• è‡ªåŠ¨å¢å¼ºæŠ¥å‘Šï¼ˆä¿®å¤è¡¨æ ¼æ ¼å¼å¹¶ç”Ÿæˆå›¾è¡¨ï¼‰
        try:
            from report_enhancer import ReportEnhancer
            enhancer = ReportEnhancer()
            enhanced_filename = enhancer.enhance_report(filename)
            print(f"\nâœ¨ æŠ¥å‘Šå·²è‡ªåŠ¨å¢å¼º: {enhanced_filename}")
            print(f"   - ä¿®å¤äº†è¡¨æ ¼æ ¼å¼")
            print(f"   - ç”Ÿæˆäº†æ•°æ®å¯è§†åŒ–å›¾è¡¨")
            print(f"   - æ¸…ç†äº†æ ¼å¼é—®é¢˜")
        except Exception as e:
            print(f"\nâš ï¸  æŠ¥å‘Šå¢å¼ºè·³è¿‡: {e}")
            print(f"   å¯ä»¥æ‰‹åŠ¨è¿è¡Œ: python report_enhancer.py {filename}")
        
        return filename
    
    def _format_report_content(self, content: str) -> str:
        """æ ¼å¼åŒ–æŠ¥å‘Šå†…å®¹ï¼ˆè½¬æ¢HTMLè¡¨æ ¼ä¸ºMarkdownï¼‰"""
        import re
        try:
            from bs4 import BeautifulSoup
            
            def html_table_to_markdown(match):
                html_table = match.group(0)
                soup = BeautifulSoup(html_table, 'html.parser')
                
                # æå–è¡¨å¤´
                headers = []
                thead = soup.find('thead')
                if thead:
                    for th in thead.find_all('th'):
                        headers.append(th.get_text().strip())
                
                # æå–è¡¨æ ¼æ•°æ®
                rows = []
                tbody = soup.find('tbody')
                if tbody:
                    for tr in tbody.find_all('tr'):
                        row = [td.get_text().strip() for td in tr.find_all('td')]
                        if row:
                            rows.append(row)
                
                # æ„å»ºMarkdownè¡¨æ ¼
                if not headers or not rows:
                    return html_table
                
                markdown = "\n"
                markdown += "| " + " | ".join(headers) + " |\n"
                markdown += "|" + "|".join(["---"] * len(headers)) + "|\n"
                for row in rows:
                    while len(row) < len(headers):
                        row.append("")
                    markdown += "| " + " | ".join(row[:len(headers)]) + " |\n"
                markdown += "\n"
                return markdown
            
            # è½¬æ¢HTMLè¡¨æ ¼
            content = re.sub(r'<table[^>]*>.*?</table>', html_table_to_markdown, content, flags=re.DOTALL)
            
            # æ¸…ç†HTMLæ ‡ç­¾
            content = re.sub(r'<h2[^>]*>(.*?)</h2>', r'### \1\n', content, flags=re.DOTALL)
            content = re.sub(r'<h3[^>]*>(.*?)</h3>', r'#### \1\n', content, flags=re.DOTALL)
            content = re.sub(r'<p[^>]*>(.*?)</p>', r'\1\n\n', content, flags=re.DOTALL)
            content = re.sub(r'<[^>]+>', '', content)
            
            # æ¸…ç†å¤šä½™ç©ºè¡Œ
            content = re.sub(r'\n{4,}', '\n\n\n', content)
            
        except ImportError:
            # å¦‚æœæ²¡æœ‰BeautifulSoupï¼Œè¿”å›åŸå†…å®¹
            pass
        except Exception:
            # å¦‚æœæ ¼å¼åŒ–å¤±è´¥ï¼Œè¿”å›åŸå†…å®¹
            pass
        
        return content
    
    def _generate_pdf_report(self, markdown_path: str, company: str, report_json: dict = None) -> str:
        """
        ç”ŸæˆPDFæŠ¥å‘Š
        
        Args:
            markdown_path: MarkdownæŠ¥å‘Šè·¯å¾„
            company: å…¬å¸åç§°
            report_json: æŠ¥å‘ŠJSONæ•°æ®ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            PDFæ–‡ä»¶è·¯å¾„
        """
        try:
            from pdf_generator import ProfessionalPDFGenerator
            import os
            
            print(f"\nğŸ“„ æ­£åœ¨ç”ŸæˆPDFæŠ¥å‘Š...")
            
            # å‡†å¤‡PDFè¾“å‡ºè·¯å¾„
            pdf_path = markdown_path.replace('.md', '.pdf')
            
            # å¦‚æœæœ‰JSONæ•°æ®ï¼Œç›´æ¥ä½¿ç”¨
            if report_json:
                # è¯»å–markdownæ–‡ä»¶è·å–å…ƒæ•°æ®å’ŒExecutive Summary
                with open(markdown_path, 'r', encoding='utf-8') as f:
                    md_content = f.read()
                
                # æå–å…ƒæ•°æ®
                import re
                metadata = {}
                timestamp_match = re.search(r'\*\*ç”Ÿæˆæ—¶é—´\*\*: (.+)', md_content)
                if timestamp_match:
                    metadata['timestamp'] = timestamp_match.group(1)
                
                queries_match = re.search(r'\*\*æŸ¥è¯¢æ•°\*\*: (\d+)/(\d+)', md_content)
                if queries_match:
                    metadata['queries_successful'] = int(queries_match.group(1))
                    metadata['queries_total'] = int(queries_match.group(2))
                
                # æå–Executive Summaryï¼ˆä»Markdownä¸­ï¼‰
                exec_summary = ""
                exec_summary_match = re.search(
                    r'## Executive Summary\s*\n(.*?)(?=\n##|\Z)',
                    md_content,
                    re.DOTALL
                )
                if exec_summary_match:
                    exec_summary = exec_summary_match.group(1).strip()
                    print(f"   âœ… Executive Summaryå·²æå– ({len(exec_summary)} å­—ç¬¦)")
                
                # æå–Referencesï¼ˆä»Markdownä¸­ï¼‰
                references = ""
                references_match = re.search(
                    r'## ğŸ“š References and Citations\s*\n(.*?)(?=\n##|\Z)',
                    md_content,
                    re.DOTALL
                )
                if references_match:
                    references = references_match.group(1).strip()
                    print(f"   âœ… Referenceså·²æå– ({len(references)} å­—ç¬¦)")
                
                # æ–‡æœ¬æ¸…ç† - ä½¿ç”¨WordFixerç›´æ¥ä¿®å¤æ‰€æœ‰é—®é¢˜
                from agents.word_fixer import WordFixer
                print("   ğŸ§¹ ä¿®å¤å•è¯æ‹†åˆ†é—®é¢˜...")
                
                # ä½¿ç”¨WordFixerç›´æ¥ä¿®å¤æ‰€æœ‰ç« èŠ‚çš„æ–‡æœ¬
                cleaned_fundamental = WordFixer.fix_all_issues(report_json.get('fundamentalAnalysis', ''))
                cleaned_business = WordFixer.fix_all_issues(report_json.get('businessSegments', ''))
                cleaned_growth = WordFixer.fix_all_issues(report_json.get('growthCatalysts', ''))
                cleaned_valuation = WordFixer.fix_all_issues(report_json.get('valuationAnalysis', ''))
                
                # å‡†å¤‡æŠ¥å‘Šæ•°æ®ï¼ˆä¸åŒ…å«Executive Summaryï¼‰
                report_data = {
                    'metadata': metadata,
                    # 'executiveSummary': exec_summary,  # å·²åˆ é™¤ï¼ˆç”¨æˆ·è¦æ±‚ï¼‰
                    'fundamentalAnalysis': cleaned_fundamental,
                    'businessSegments': cleaned_business,
                    'growthCatalysts': cleaned_growth,
                    'valuationAnalysis': cleaned_valuation
                }
                
                # å¦‚æœæœ‰AIæ´å¯Ÿï¼Œä¹ŸåŒ…å«è¿›å»ï¼ˆä½¿ç”¨WordFixerä¿®å¤ï¼‰
                if 'aiInsights' in report_json:
                    report_data['aiInsights'] = WordFixer.fix_all_issues(report_json['aiInsights'])
                    print(f"   âœ… AI Insightså·²åŒ…å«ï¼ˆå·²ä¿®å¤ï¼‰")
                
                # å¦‚æœæœ‰Referencesï¼Œä¹ŸåŒ…å«è¿›å»ï¼ˆä½¿ç”¨WordFixerä¿®å¤ï¼‰
                if references:
                    report_data['references'] = WordFixer.fix_all_issues(references)
                    print(f"   âœ… Referenceså·²åŒ…å«ï¼ˆå·²ä¿®å¤ï¼‰")
                
                # ç”ŸæˆPDF
                generator = ProfessionalPDFGenerator()
                generator.generate_report_pdf(company, report_data, pdf_path)
                
            else:
                # ä»Markdownè½¬æ¢ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
                from pdf_generator import convert_markdown_to_pdf
                pdf_path = convert_markdown_to_pdf(markdown_path)
            
            return pdf_path
            
        except Exception as e:
            print(f"\nâš ï¸  PDFç”Ÿæˆå¤±è´¥: {e}")
            print(f"   MarkdownæŠ¥å‘Šä»ç„¶å¯ç”¨: {markdown_path}")
            import traceback
            traceback.print_exc()
            return None
    
    def quick_analysis(self, company: str) -> str:
        """å¿«é€Ÿåˆ†æï¼ˆä¾¿æ·æ–¹æ³•ï¼‰"""
        result = self.generate_report(company, report_type="quick", save_to_file=False)
        if result["status"] == "success":
            return result["report"]
        else:
            return f"åˆ†æå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"
    
    def compare_companies(self, companies: list) -> dict:
        """æ¯”è¾ƒå¤šä¸ªå…¬å¸"""
        print(f"ğŸ”„ æ¯”è¾ƒåˆ†æ: {', '.join(companies)}")
        
        companies_data = {}
        
        for company in companies:
            print(f"\næ­£åœ¨æ”¶é›† {company} çš„ä¿¡æ¯...")
            query_plan = self.query_planner.generate_search_plan(company)
            collection_result = self.information_collector.collect_information(query_plan)
            companies_data[company] = self.information_collector.format_for_analysis(
                collection_result
            )
        
        print("\næ­£åœ¨ç”Ÿæˆæ¯”è¾ƒåˆ†æ...")
        comparison_result = self.deep_analyst.compare_companies(companies_data)
        
        return comparison_result


def main():
    """ä¸»å‡½æ•° - ç¤ºä¾‹ç”¨æ³•"""
    # åˆ›å»ºç³»ç»Ÿå®ä¾‹
    system = ValuationReportSystem()
    
    # ç¤ºä¾‹1: ç”Ÿæˆå•ä¸ªå…¬å¸çš„å®Œæ•´æŠ¥å‘Š
    print("\nç¤ºä¾‹1: å®Œæ•´ä¼°å€¼æŠ¥å‘Š")
    result = system.generate_report(
        company="Apple Inc",
        analysis_type="valuation",
        report_type="comprehensive",
        save_to_file=True
    )
    
    if result["status"] == "success":
        print("\næŠ¥å‘Šé¢„è§ˆ:")
        print(result["report"][:500] + "...\n")
    
    # ç¤ºä¾‹2: å¿«é€Ÿåˆ†æ
    # print("\nç¤ºä¾‹2: å¿«é€Ÿåˆ†æ")
    # summary = system.quick_analysis("Tesla")
    # print(summary)
    
    # ç¤ºä¾‹3: æ¯”è¾ƒå¤šä¸ªå…¬å¸
    # print("\nç¤ºä¾‹3: æ¯”è¾ƒåˆ†æ")
    # comparison = system.compare_companies(["Apple", "Microsoft", "Google"])
    # print(comparison["comparison"])


if __name__ == "__main__":
    main()

