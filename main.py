"""
æ·±åº¦ä¼°å€¼æŠ¥å‘Šç³»ç»Ÿ - ä¸»ç¨‹åº
æ•´åˆSonarå®æ—¶æœç´¢å’ŒQwen3Maxæ·±åº¦æ¨ç†
"""
import time
from datetime import datetime
from typing import Optional
from agents import QueryPlannerAgent, InformationCollectorAgent, DeepAnalystAgent
from agents.professional_formatter import ProfessionalReportFormatter
from api_clients import SonarClient, QwenClient


class ValuationReportSystem:
    """
    ä¼°å€¼æŠ¥å‘Šç³»ç»Ÿä¸»ç±»
    
    æ¶æ„ï¼š
    1. QueryPlanner (Qwenè½»é‡) -> ç”Ÿæˆç²¾ç¡®æŸ¥è¯¢è®¡åˆ’
    2. InformationCollector (Sonarå¹¶è¡Œ) -> æ”¶é›†å®æ—¶ä¿¡æ¯
    3. DeepAnalyst (Qwenæ·±åº¦) -> ç”Ÿæˆä¸“ä¸šæŠ¥å‘Š
    """
    
    def __init__(self):
        # åˆå§‹åŒ–APIå®¢æˆ·ç«¯
        self.sonar_client = SonarClient()
        self.qwen_client = QwenClient()
        
        # åˆå§‹åŒ–Agents
        self.query_planner = QueryPlannerAgent(self.qwen_client)
        self.information_collector = InformationCollectorAgent(self.sonar_client)
        self.deep_analyst = DeepAnalystAgent(self.qwen_client)
        self.professional_formatter = ProfessionalReportFormatter()
        
    def generate_report(
        self,
        company: str,
        analysis_type: str = "valuation",
        report_type: str = "comprehensive",
        save_to_file: bool = True
    ) -> dict:
        """
        ç”Ÿæˆå®Œæ•´çš„ä¼°å€¼æŠ¥å‘Š
        
        Args:
            company: å…¬å¸åç§°æˆ–è‚¡ç¥¨ä»£ç 
            analysis_type: åˆ†æç±»å‹
            report_type: æŠ¥å‘Šç±»å‹ï¼ˆcomprehensive=ç»¼åˆ, quick=å¿«é€Ÿï¼‰
            save_to_file: æ˜¯å¦ä¿å­˜åˆ°æ–‡ä»¶
            
        Returns:
            åŒ…å«æŠ¥å‘Šå†…å®¹çš„å­—å…¸
        """
        print("="*80)
        print(f"ğŸš€ æ·±åº¦ä¼°å€¼æŠ¥å‘Šç³»ç»Ÿ")
        print(f"ğŸ“Š åˆ†æå¯¹è±¡: {company}")
        print(f"â° å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("="*80)
        
        start_time = time.time()
        
        # é˜¶æ®µ1: æŸ¥è¯¢è§„åˆ’ï¼ˆQwenè½»é‡è°ƒç”¨ï¼‰
        print("\nã€é˜¶æ®µ1/3ã€‘æŸ¥è¯¢è§„åˆ’")
        print("-"*80)
        query_plan = self.query_planner.generate_search_plan(company, analysis_type)
        
        if query_plan["status"] != "success":
            return {"status": "error", "error": "æŸ¥è¯¢è§„åˆ’å¤±è´¥"}
        
        print(f"âœ… ç”Ÿæˆäº† {len(query_plan['plan']['queries'])} ä¸ªæœç´¢æŸ¥è¯¢")
        for i, q in enumerate(query_plan['plan']['queries'], 1):
            print(f"   {i}. [{q['priority']}] {q['purpose']}: {q['query'][:60]}...")
        
        # é˜¶æ®µ2: ä¿¡æ¯æ”¶é›†ï¼ˆSonarå¹¶è¡Œè°ƒç”¨ï¼‰
        print("\nã€é˜¶æ®µ2/3ã€‘ä¿¡æ¯æ”¶é›†")
        print("-"*80)
        collection_result = self.information_collector.collect_information(query_plan)
        
        if collection_result["status"] != "success":
            return {"status": "error", "error": "ä¿¡æ¯æ”¶é›†å¤±è´¥"}
        
        # æ ¼å¼åŒ–ä¿¡æ¯ç”¨äºåˆ†æ
        formatted_info = self.information_collector.format_for_analysis(collection_result)
        
        # é˜¶æ®µ3: æ·±åº¦åˆ†æï¼ˆQwenæ·±åº¦æ¨ç†ï¼‰
        print("\nã€é˜¶æ®µ3/3ã€‘æ·±åº¦åˆ†æ")
        print("-"*80)
        
        if report_type == "quick":
            analysis_result = self.deep_analyst.generate_quick_summary(company, formatted_info)
        else:
            analysis_result = self.deep_analyst.generate_valuation_report(
                company,
                formatted_info,
                report_type
            )
        
        if analysis_result["status"] != "success":
            error_msg = analysis_result.get("error", "æœªçŸ¥é”™è¯¯")
            print(f"âŒ æ·±åº¦åˆ†æé”™è¯¯è¯¦æƒ…: {error_msg}")
            return {"status": "error", "error": f"æ·±åº¦åˆ†æå¤±è´¥: {error_msg}"}
        
        # è®¡ç®—æ€»è€—æ—¶
        elapsed_time = time.time() - start_time
        
        # å¦‚æœæŠ¥å‘ŠåŒ…å«JSONï¼Œæ›´æ–°å…ƒæ•°æ®å¹¶é‡æ–°æ ¼å¼åŒ–
        if "report_json" in analysis_result and analysis_result.get("report_json"):
            metadata = {
                "elapsed_time": elapsed_time,
                "queries_successful": collection_result["success_count"],
                "queries_executed": collection_result["total_queries"]
            }
            
            # æ”¶é›†æ‰€æœ‰citations
            all_citations = []
            for result in collection_result.get("results", []):
                if result.get("status") == "success" and result.get("citations"):
                    for citation in result["citations"]:
                        if citation not in all_citations:  # å»é‡
                            all_citations.append(citation)
            
            # é‡æ–°ç”Ÿæˆä¸“ä¸šæ ¼å¼æŠ¥å‘Šï¼ˆå¸¦æ­£ç¡®çš„å…ƒæ•°æ®å’Œcitationsï¼‰
            analysis_result["report"] = self.professional_formatter.format_professional_report(
                company,
                analysis_result["report_json"],
                metadata,
                citations=all_citations
            )
        
        print("\n" + "="*80)
        print(f"âœ… æŠ¥å‘Šç”Ÿæˆå®Œæˆ!")
        print(f"â±ï¸  æ€»è€—æ—¶: {elapsed_time:.2f}ç§’")
        print("="*80)
        
        # å‡†å¤‡è¾“å‡ºç»“æœ
        result = {
            "status": "success",
            "company": company,
            "report": analysis_result.get("report") or analysis_result.get("summary"),
            "metadata": {
                "analysis_type": analysis_type,
                "report_type": report_type,
                "queries_executed": collection_result["total_queries"],
                "queries_successful": collection_result["success_count"],
                "elapsed_time": elapsed_time,
                "timestamp": datetime.now().isoformat()
            }
        }
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        if save_to_file:
            filename = self._save_report(company, result)
            result["metadata"]["saved_file"] = filename
            print(f"ğŸ’¾ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {filename}")
        
        return result
    
    def _save_report(self, company: str, result: dict) -> str:
        """ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶ï¼ˆè‡ªåŠ¨æ ¼å¼åŒ–ï¼‰"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        safe_company = company.replace(" ", "_").replace("/", "_")
        filename = f"reports/{safe_company}_{timestamp}.md"
        
        # åˆ›å»ºreportsç›®å½•
        import os
        os.makedirs("reports", exist_ok=True)
        
        # å‡†å¤‡æŠ¥å‘Šå†…å®¹
        report_content = f"# {company} ä¼°å€¼æŠ¥å‘Š\n\n"
        report_content += f"**ç”Ÿæˆæ—¶é—´**: {result['metadata']['timestamp']}\n\n"
        report_content += f"**åˆ†æç±»å‹**: {result['metadata']['analysis_type']} | "
        report_content += f"**æŸ¥è¯¢æ•°**: {result['metadata']['queries_successful']}/{result['metadata']['queries_executed']} | "
        report_content += f"**è€—æ—¶**: {result['metadata']['elapsed_time']:.2f}ç§’\n\n"
        report_content += "---\n\n"
        report_content += result["report"]
        
        # æ ¼å¼åŒ–æŠ¥å‘Šï¼ˆè½¬æ¢HTMLè¡¨æ ¼ä¸ºMarkdownï¼‰
        formatted_content = self._format_report_content(report_content)
        
        # å†™å…¥æŠ¥å‘Š
        with open(filename, "w", encoding="utf-8") as f:
            f.write(formatted_content)
        
        # ğŸ†• è‡ªåŠ¨å¢å¼ºæŠ¥å‘Šï¼ˆä¿®å¤è¡¨æ ¼æ ¼å¼å¹¶ç”Ÿæˆå›¾è¡¨ï¼‰
        try:
            from report_enhancer import ReportEnhancer
            enhancer = ReportEnhancer()
            enhanced_filename = enhancer.enhance_report(filename)
            print(f"\nâœ¨ æŠ¥å‘Šå·²è‡ªåŠ¨å¢å¼º: {enhanced_filename}")
            print(f"   - ä¿®å¤äº†è¡¨æ ¼æ ¼å¼")
            print(f"   - ç”Ÿæˆäº†æ•°æ®å¯è§†åŒ–å›¾è¡¨")
            print(f"   - æ¸…ç†äº†æ ¼å¼é—®é¢˜")
        except Exception as e:
            print(f"\nâš ï¸  æŠ¥å‘Šå¢å¼ºè·³è¿‡: {e}")
            print(f"   å¯ä»¥æ‰‹åŠ¨è¿è¡Œ: python report_enhancer.py {filename}")
        
        return filename
    
    def _format_report_content(self, content: str) -> str:
        """æ ¼å¼åŒ–æŠ¥å‘Šå†…å®¹ï¼ˆè½¬æ¢HTMLè¡¨æ ¼ä¸ºMarkdownï¼‰"""
        import re
        try:
            from bs4 import BeautifulSoup
            
            def html_table_to_markdown(match):
                html_table = match.group(0)
                soup = BeautifulSoup(html_table, 'html.parser')
                
                # æå–è¡¨å¤´
                headers = []
                thead = soup.find('thead')
                if thead:
                    for th in thead.find_all('th'):
                        headers.append(th.get_text().strip())
                
                # æå–è¡¨æ ¼æ•°æ®
                rows = []
                tbody = soup.find('tbody')
                if tbody:
                    for tr in tbody.find_all('tr'):
                        row = [td.get_text().strip() for td in tr.find_all('td')]
                        if row:
                            rows.append(row)
                
                # æ„å»ºMarkdownè¡¨æ ¼
                if not headers or not rows:
                    return html_table
                
                markdown = "\n"
                markdown += "| " + " | ".join(headers) + " |\n"
                markdown += "|" + "|".join(["---"] * len(headers)) + "|\n"
                for row in rows:
                    while len(row) < len(headers):
                        row.append("")
                    markdown += "| " + " | ".join(row[:len(headers)]) + " |\n"
                markdown += "\n"
                return markdown
            
            # è½¬æ¢HTMLè¡¨æ ¼
            content = re.sub(r'<table[^>]*>.*?</table>', html_table_to_markdown, content, flags=re.DOTALL)
            
            # æ¸…ç†HTMLæ ‡ç­¾
            content = re.sub(r'<h2[^>]*>(.*?)</h2>', r'### \1\n', content, flags=re.DOTALL)
            content = re.sub(r'<h3[^>]*>(.*?)</h3>', r'#### \1\n', content, flags=re.DOTALL)
            content = re.sub(r'<p[^>]*>(.*?)</p>', r'\1\n\n', content, flags=re.DOTALL)
            content = re.sub(r'<[^>]+>', '', content)
            
            # æ¸…ç†å¤šä½™ç©ºè¡Œ
            content = re.sub(r'\n{4,}', '\n\n\n', content)
            
        except ImportError:
            # å¦‚æœæ²¡æœ‰BeautifulSoupï¼Œè¿”å›åŸå†…å®¹
            pass
        except Exception:
            # å¦‚æœæ ¼å¼åŒ–å¤±è´¥ï¼Œè¿”å›åŸå†…å®¹
            pass
        
        return content
    
    def quick_analysis(self, company: str) -> str:
        """å¿«é€Ÿåˆ†æï¼ˆä¾¿æ·æ–¹æ³•ï¼‰"""
        result = self.generate_report(company, report_type="quick", save_to_file=False)
        if result["status"] == "success":
            return result["report"]
        else:
            return f"åˆ†æå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}"
    
    def compare_companies(self, companies: list) -> dict:
        """æ¯”è¾ƒå¤šä¸ªå…¬å¸"""
        print(f"ğŸ”„ æ¯”è¾ƒåˆ†æ: {', '.join(companies)}")
        
        companies_data = {}
        
        for company in companies:
            print(f"\næ­£åœ¨æ”¶é›† {company} çš„ä¿¡æ¯...")
            query_plan = self.query_planner.generate_search_plan(company)
            collection_result = self.information_collector.collect_information(query_plan)
            companies_data[company] = self.information_collector.format_for_analysis(
                collection_result
            )
        
        print("\næ­£åœ¨ç”Ÿæˆæ¯”è¾ƒåˆ†æ...")
        comparison_result = self.deep_analyst.compare_companies(companies_data)
        
        return comparison_result


def main():
    """ä¸»å‡½æ•° - ç¤ºä¾‹ç”¨æ³•"""
    # åˆ›å»ºç³»ç»Ÿå®ä¾‹
    system = ValuationReportSystem()
    
    # ç¤ºä¾‹1: ç”Ÿæˆå•ä¸ªå…¬å¸çš„å®Œæ•´æŠ¥å‘Š
    print("\nç¤ºä¾‹1: å®Œæ•´ä¼°å€¼æŠ¥å‘Š")
    result = system.generate_report(
        company="Apple Inc",
        analysis_type="valuation",
        report_type="comprehensive",
        save_to_file=True
    )
    
    if result["status"] == "success":
        print("\næŠ¥å‘Šé¢„è§ˆ:")
        print(result["report"][:500] + "...\n")
    
    # ç¤ºä¾‹2: å¿«é€Ÿåˆ†æ
    # print("\nç¤ºä¾‹2: å¿«é€Ÿåˆ†æ")
    # summary = system.quick_analysis("Tesla")
    # print(summary)
    
    # ç¤ºä¾‹3: æ¯”è¾ƒå¤šä¸ªå…¬å¸
    # print("\nç¤ºä¾‹3: æ¯”è¾ƒåˆ†æ")
    # comparison = system.compare_companies(["Apple", "Microsoft", "Google"])
    # print(comparison["comparison"])


if __name__ == "__main__":
    main()

